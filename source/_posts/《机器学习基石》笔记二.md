---
title: 《机器学习基石》笔记二
date: 2018-05-16 21:51:53
tags: [机器学习,笔记]
mathjax: true
---
# 回顾

上一章中讲到了一些机器学习的基本概念，通过介绍银行信用卡派发系统，我们大致了解了机器学习的过程。如下图所示，根据银行现有的数据集$D = \{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\}$，其中$x_n$是一个向量，表示第$n$个申请人的信息，$y_n$是一个二值(是/否)变量，表示是否给该人派发信用卡。我们认为，$f$是理论上正确的，可准确描述$x\longrightarrow y$这个过程的函数。

![](\images\TIM截图20180515115344.png)

从图中我们可以看出用机器学习来决策是否给某位新用户$x$派发信用卡的过程为：

> **取已有的数据集作为训练集，运用算法$A$，从所有的假设函数中，选出性能最好的、最接近$f$的决策函数$g$**

那么，假设函数$h$又是什么呢？我们该如何选择？

# 感知器(perceptron)

![](\images\TIM截图20180515134337.png)

我们认为顾客各项特征的重要性是不等的，所以给每项特征值赋予不同的权重，将特征加权求和结果作为得分score。选定一个阈值，当score大于这个阈值时，建议给该人派发信用卡，否则拒绝申请。

所以，我们的假设函数可以写成：
> $h(x) = sign((\sum_{i=1}^dw_ix_i)-threshold)$

上式可进行如下转化。通过添加一个$x_0=+1$，将threshold作为其权重$w_0$，$h(x)$可写成下面的形式：

![](\images\TIM截图20180515141925.png)

所以，$H$是一个函数集，不同的$w_0, w_1, ... ,w_n$的组合确定了不同的假设函数$h(x)$。

对于一个新的需要决策的输入数据$x$，将其代入假设函数，得到的结果即为该感知器的决策。

下面我们来直观的理解一下$h(x)$。

我们可以想象每个$x$在平面内都有一个对应的位置，由于$y$值有两种，所以分别用‘x’和'o'分别标记这两类$x$。当$x=(x_1, x_2)$，是一个二维向量的时候，$h(x) = sign(w_0 + w_1x_1 + w_2x_2)$。这时，$h(x)$可以看成平面上的一条直线，这条直线可以将平面分成两部分，同理这些点也分成了两部分。

$h(x)$的目的就是要尽可能将'x'和'o'这两类点放在直线的两侧。下图中，我们可以看出，右边的直线比左边的更能y有效区分这些点。

![](\images\TIM截图20180515150502.png)

所以，当使用某个$h(x)$来进行决策的时候，只需要看看输入数据在直线的哪一侧即可。

当$x$是三维的话，相当于在空间中找一个平面来划分点。同理，可以推广到多维空间。

![](\images\TIM截图20180515152628.png)

所以，感知器可以看成是一种线性分类器。

## g的选取

![](\images\TIM截图20180516102002.png)]

前面得到的$H$是一系列假设函数的集合，如何从其中找到最接近$f$的$g$呢？

$f$是理想、未知的映射函数，要找到$g$满足$g\approx f$。首先必须满足，在几乎所有训练集上$g(x_i) = f(x_i) = y_i $要成立。

